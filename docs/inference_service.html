<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>inference_service API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>inference_service</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import requests
import os
import logging as log
from typing import List, Tuple
from models.image import Image

from models.detection_result import DetectionResult, DetectionResultsDecoder
from services.image_processing_service import ImageProcessingService
from utils.exceptions import (
    PotentialObjectNotFoundException,
    CarNotFoundException,
    LicensePlateNotFoundException,
    CharactersCouldNotBeRecognizedByOCR,
)
from models.ocr_result import OcrResult

# API for object detection (it runs TF Hub&#39;s model)
predict_api_address_env = os.environ.get(&#34;PREDICT_API&#34;)
predict_api_host = (
    predict_api_address_env
    if predict_api_address_env is not None
    else &#34;predict-api:5000&#34;
)

# OCR server address for sending image with license plate to recognize characters
ocr_server_address_env = os.environ.get(&#34;OCR_SERVER&#34;)
ocr_server_host = (
    ocr_server_address_env if ocr_server_address_env is not None else &#34;ocr:5000&#34;
)

log.basicConfig(level=log.DEBUG, format=&#34;%(asctime)s - %(message)s&#34;)
log.info(&#34;Predict API address: %s&#34;, predict_api_host)
log.info(&#34;OCR server address: %s&#34;, ocr_server_host)


class InferenceService:
    _bottom_of_car_box: List[float] = [0.25, 0.0, 1.0, 1.0]
    _car_class_entity: str = &#34;Car&#34;
    _license_plate_class_entity: str = &#34;Vehicle registration plate&#34;

    def send_image_to_detector(self, image: Image) -&gt; List[DetectionResult]:
        &#34;&#34;&#34;Sends image to predict api, which returns JSON with predictions about objects in that image.
        Before sending image, it needs to be encoded in base64.
        &#34;&#34;&#34;
        image_base64 = image.to_base64()

        response = requests.post(
            f&#34;http://{predict_api_host}/predict&#34;,
            json={&#34;imgBase64&#34;: image_base64},
        )

        results = DetectionResultsDecoder().decode(response.text)

        return results

    def send_image_to_ocr(self, image: Image) -&gt; OcrResult:
        image_base64 = image.to_base64()

        response = requests.post(
            f&#34;http://{ocr_server_host}/ocr/base64&#34;,
            json={&#34;b64Encoded&#34;: image_base64},
        )

        print(response.status_code)
        if response.status_code != 200:
            raise CharactersCouldNotBeRecognizedByOCR

        return OcrResult.from_json(response.json())

    def find_potential_object(
        self,
        results: List[DetectionResult],
        area_threshold: int,
        score_threshold: float,
    ) -&gt; DetectionResult:
        &#34;&#34;&#34;Returns one result, which area and score is above given thresholds.
        If more than one result comply with conditions, one with the biggest score is returned.

        Function doesn&#39;t filter passed results by class_entity.
        So it&#39;s needed to pass filtered ones if you want find e.g. potential car.
        &#34;&#34;&#34;
        max_score = 0
        index = -1

        for i in range(len(results)):
            area = results[i].get_percent_of_area()
            score = results[i].score

            if score &gt; max_score and area &gt; area_threshold and score &gt;= score_threshold:
                max_score = score
                index = i

        if index == -1:
            message = (
                &#34;Not found potential object for thresholds: &#34;
                + f&#34;area: {area_threshold}, score: {score_threshold}&#34;
            )

            raise PotentialObjectNotFoundException(message)

        return results[index]

    def get_results_and_cropped_image_for_potential_object_of_class_entity(
        self,
        image: Image,
        class_entity: str,
        area_threshold: int = 20,
        score_threshold: float = 0.2,
    ) -&gt; Tuple[List[DetectionResult], DetectionResult, Image]:
        &#34;&#34;&#34;Returns filtered result, result with potential object and image with that potential object.

        Sends image to predict api for getting object detection result.
        Then filters that result by class_entity (e.g. &#34;Car&#34;)
        and trying to find potential object of class_entity.
        If potential object is found, image is cropped to its box and returned.
        &#34;&#34;&#34;

        result = self.send_image_to_detector(image)
        result_filtered_by_class_entity = list(
            filter(
                lambda r: r.class_entity == class_entity,
                result,
            )
        )

        log.debug(result_filtered_by_class_entity)

        try:
            detection_result_of_potential_object = self.find_potential_object(
                result_filtered_by_class_entity,
                area_threshold=area_threshold,
                score_threshold=score_threshold,
            )
        except PotentialObjectNotFoundException:
            raise

        cropped_image_with_potential_object = ImageProcessingService.crop_image(
            image, detection_result_of_potential_object.box
        )

        return (
            result_filtered_by_class_entity,
            detection_result_of_potential_object,
            cropped_image_with_potential_object,
        )

    def get_license_plate_number(self, image: Image) -&gt; OcrResult:
        &#34;&#34;&#34;Returns object with results given by OCR after some image processing.

        At first, it looks for potential car in image.
        Then crops image to slice, which contains bottom of the car.
        Then it looks for potential license plate in that slice,
        crops that slice (so now it should be slice with license plate)
        and sends that cropped image to OCR.
        &#34;&#34;&#34;

        try:
            (
                first_result,
                potential_car,
                cropped_car,
            ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
                image,
                self._car_class_entity,
                area_threshold=0,
                score_threshold=0.0,
            )
        except PotentialObjectNotFoundException as e:
            log.error(e)
            raise CarNotFoundException()

        image_with_boxes_for_car = (
            ImageProcessingService.draw_bounding_boxes_with_class_entity(
                image, first_result, max_number_of_boxes=5, show_only_score=True
            )
        )
        image_with_boxes_for_car.save(filename_sufix=&#34;car&#34;)

        image_links = {}
        image_links[&#34;car-boxes&#34;] = image_with_boxes_for_car.save_to_minio(
            filename_sufix=&#34;car-boxes&#34;
        )

        image_with_bottom_of_car = ImageProcessingService.crop_image(
            cropped_car, self._bottom_of_car_box
        )
        image_with_bottom_of_car.save(filename_sufix=&#34;bottom-car&#34;)
        image_links[&#34;cropped-car&#34;] = cropped_car.save_to_minio(
            filename_sufix=&#34;cropped-car&#34;
        )
        image_links[&#34;bottom-of-car&#34;] = image_with_bottom_of_car.save_to_minio(
            filename_sufix=&#34;bottom-of-car&#34;
        )

        try:
            (
                second_result,
                potential_license_plate,
                cropped_license_plate,
            ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
                image_with_bottom_of_car,
                self._license_plate_class_entity,
                area_threshold=0,
                score_threshold=0.0,
            )
        except PotentialObjectNotFoundException as e:
            log.error(e)
            raise LicensePlateNotFoundException

        cropped_license_plate.save(filename_sufix=&#34;cropped-license-plate&#34;)
        image_links[&#34;cropped-license-plate&#34;] = cropped_license_plate.save_to_minio(
            filename_sufix=&#34;cropped-license-plate&#34;
        )

        image_with_boxes_for_plate = (
            ImageProcessingService.draw_bounding_boxes_with_class_entity(
                image_with_bottom_of_car,
                second_result,
                max_number_of_boxes=5,
                show_only_score=True,
            )
        )
        image_with_boxes_for_plate.save(filename_sufix=&#34;license-plate&#34;)
        image_links[&#34;license-plate-boxes&#34;] = image_with_boxes_for_plate.save_to_minio(
            filename_sufix=&#34;license-plate-boxes&#34;
        )

        try:
            ocr_result = self.send_image_to_ocr(cropped_license_plate)
        except CharactersCouldNotBeRecognizedByOCR:
            raise

        log.debug(ocr_result)

        ocr_result.image_links.update(**image_links)

        return ocr_result</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="inference_service.InferenceService"><code class="flex name class">
<span>class <span class="ident">InferenceService</span></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InferenceService:
    _bottom_of_car_box: List[float] = [0.25, 0.0, 1.0, 1.0]
    _car_class_entity: str = &#34;Car&#34;
    _license_plate_class_entity: str = &#34;Vehicle registration plate&#34;

    def send_image_to_detector(self, image: Image) -&gt; List[DetectionResult]:
        &#34;&#34;&#34;Sends image to predict api, which returns JSON with predictions about objects in that image.
        Before sending image, it needs to be encoded in base64.
        &#34;&#34;&#34;
        image_base64 = image.to_base64()

        response = requests.post(
            f&#34;http://{predict_api_host}/predict&#34;,
            json={&#34;imgBase64&#34;: image_base64},
        )

        results = DetectionResultsDecoder().decode(response.text)

        return results

    def send_image_to_ocr(self, image: Image) -&gt; OcrResult:
        image_base64 = image.to_base64()

        response = requests.post(
            f&#34;http://{ocr_server_host}/ocr/base64&#34;,
            json={&#34;b64Encoded&#34;: image_base64},
        )

        print(response.status_code)
        if response.status_code != 200:
            raise CharactersCouldNotBeRecognizedByOCR

        return OcrResult.from_json(response.json())

    def find_potential_object(
        self,
        results: List[DetectionResult],
        area_threshold: int,
        score_threshold: float,
    ) -&gt; DetectionResult:
        &#34;&#34;&#34;Returns one result, which area and score is above given thresholds.
        If more than one result comply with conditions, one with the biggest score is returned.

        Function doesn&#39;t filter passed results by class_entity.
        So it&#39;s needed to pass filtered ones if you want find e.g. potential car.
        &#34;&#34;&#34;
        max_score = 0
        index = -1

        for i in range(len(results)):
            area = results[i].get_percent_of_area()
            score = results[i].score

            if score &gt; max_score and area &gt; area_threshold and score &gt;= score_threshold:
                max_score = score
                index = i

        if index == -1:
            message = (
                &#34;Not found potential object for thresholds: &#34;
                + f&#34;area: {area_threshold}, score: {score_threshold}&#34;
            )

            raise PotentialObjectNotFoundException(message)

        return results[index]

    def get_results_and_cropped_image_for_potential_object_of_class_entity(
        self,
        image: Image,
        class_entity: str,
        area_threshold: int = 20,
        score_threshold: float = 0.2,
    ) -&gt; Tuple[List[DetectionResult], DetectionResult, Image]:
        &#34;&#34;&#34;Returns filtered result, result with potential object and image with that potential object.

        Sends image to predict api for getting object detection result.
        Then filters that result by class_entity (e.g. &#34;Car&#34;)
        and trying to find potential object of class_entity.
        If potential object is found, image is cropped to its box and returned.
        &#34;&#34;&#34;

        result = self.send_image_to_detector(image)
        result_filtered_by_class_entity = list(
            filter(
                lambda r: r.class_entity == class_entity,
                result,
            )
        )

        log.debug(result_filtered_by_class_entity)

        try:
            detection_result_of_potential_object = self.find_potential_object(
                result_filtered_by_class_entity,
                area_threshold=area_threshold,
                score_threshold=score_threshold,
            )
        except PotentialObjectNotFoundException:
            raise

        cropped_image_with_potential_object = ImageProcessingService.crop_image(
            image, detection_result_of_potential_object.box
        )

        return (
            result_filtered_by_class_entity,
            detection_result_of_potential_object,
            cropped_image_with_potential_object,
        )

    def get_license_plate_number(self, image: Image) -&gt; OcrResult:
        &#34;&#34;&#34;Returns object with results given by OCR after some image processing.

        At first, it looks for potential car in image.
        Then crops image to slice, which contains bottom of the car.
        Then it looks for potential license plate in that slice,
        crops that slice (so now it should be slice with license plate)
        and sends that cropped image to OCR.
        &#34;&#34;&#34;

        try:
            (
                first_result,
                potential_car,
                cropped_car,
            ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
                image,
                self._car_class_entity,
                area_threshold=0,
                score_threshold=0.0,
            )
        except PotentialObjectNotFoundException as e:
            log.error(e)
            raise CarNotFoundException()

        image_with_boxes_for_car = (
            ImageProcessingService.draw_bounding_boxes_with_class_entity(
                image, first_result, max_number_of_boxes=5, show_only_score=True
            )
        )
        image_with_boxes_for_car.save(filename_sufix=&#34;car&#34;)

        image_links = {}
        image_links[&#34;car-boxes&#34;] = image_with_boxes_for_car.save_to_minio(
            filename_sufix=&#34;car-boxes&#34;
        )

        image_with_bottom_of_car = ImageProcessingService.crop_image(
            cropped_car, self._bottom_of_car_box
        )
        image_with_bottom_of_car.save(filename_sufix=&#34;bottom-car&#34;)
        image_links[&#34;cropped-car&#34;] = cropped_car.save_to_minio(
            filename_sufix=&#34;cropped-car&#34;
        )
        image_links[&#34;bottom-of-car&#34;] = image_with_bottom_of_car.save_to_minio(
            filename_sufix=&#34;bottom-of-car&#34;
        )

        try:
            (
                second_result,
                potential_license_plate,
                cropped_license_plate,
            ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
                image_with_bottom_of_car,
                self._license_plate_class_entity,
                area_threshold=0,
                score_threshold=0.0,
            )
        except PotentialObjectNotFoundException as e:
            log.error(e)
            raise LicensePlateNotFoundException

        cropped_license_plate.save(filename_sufix=&#34;cropped-license-plate&#34;)
        image_links[&#34;cropped-license-plate&#34;] = cropped_license_plate.save_to_minio(
            filename_sufix=&#34;cropped-license-plate&#34;
        )

        image_with_boxes_for_plate = (
            ImageProcessingService.draw_bounding_boxes_with_class_entity(
                image_with_bottom_of_car,
                second_result,
                max_number_of_boxes=5,
                show_only_score=True,
            )
        )
        image_with_boxes_for_plate.save(filename_sufix=&#34;license-plate&#34;)
        image_links[&#34;license-plate-boxes&#34;] = image_with_boxes_for_plate.save_to_minio(
            filename_sufix=&#34;license-plate-boxes&#34;
        )

        try:
            ocr_result = self.send_image_to_ocr(cropped_license_plate)
        except CharactersCouldNotBeRecognizedByOCR:
            raise

        log.debug(ocr_result)

        ocr_result.image_links.update(**image_links)

        return ocr_result</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="inference_service.InferenceService.find_potential_object"><code class="name flex">
<span>def <span class="ident">find_potential_object</span></span>(<span>self, results: List[models.detection_result.DetectionResult], area_threshold: int, score_threshold: float) ‑> models.detection_result.DetectionResult</span>
</code></dt>
<dd>
<div class="desc"><p>Returns one result, which area and score is above given thresholds.
If more than one result comply with conditions, one with the biggest score is returned.</p>
<p>Function doesn't filter passed results by class_entity.
So it's needed to pass filtered ones if you want find e.g. potential car.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_potential_object(
    self,
    results: List[DetectionResult],
    area_threshold: int,
    score_threshold: float,
) -&gt; DetectionResult:
    &#34;&#34;&#34;Returns one result, which area and score is above given thresholds.
    If more than one result comply with conditions, one with the biggest score is returned.

    Function doesn&#39;t filter passed results by class_entity.
    So it&#39;s needed to pass filtered ones if you want find e.g. potential car.
    &#34;&#34;&#34;
    max_score = 0
    index = -1

    for i in range(len(results)):
        area = results[i].get_percent_of_area()
        score = results[i].score

        if score &gt; max_score and area &gt; area_threshold and score &gt;= score_threshold:
            max_score = score
            index = i

    if index == -1:
        message = (
            &#34;Not found potential object for thresholds: &#34;
            + f&#34;area: {area_threshold}, score: {score_threshold}&#34;
        )

        raise PotentialObjectNotFoundException(message)

    return results[index]</code></pre>
</details>
</dd>
<dt id="inference_service.InferenceService.get_license_plate_number"><code class="name flex">
<span>def <span class="ident">get_license_plate_number</span></span>(<span>self, image: models.image.Image) ‑> models.ocr_result.OcrResult</span>
</code></dt>
<dd>
<div class="desc"><p>Returns object with results given by OCR after some image processing.</p>
<p>At first, it looks for potential car in image.
Then crops image to slice, which contains bottom of the car.
Then it looks for potential license plate in that slice,
crops that slice (so now it should be slice with license plate)
and sends that cropped image to OCR.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_license_plate_number(self, image: Image) -&gt; OcrResult:
    &#34;&#34;&#34;Returns object with results given by OCR after some image processing.

    At first, it looks for potential car in image.
    Then crops image to slice, which contains bottom of the car.
    Then it looks for potential license plate in that slice,
    crops that slice (so now it should be slice with license plate)
    and sends that cropped image to OCR.
    &#34;&#34;&#34;

    try:
        (
            first_result,
            potential_car,
            cropped_car,
        ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
            image,
            self._car_class_entity,
            area_threshold=0,
            score_threshold=0.0,
        )
    except PotentialObjectNotFoundException as e:
        log.error(e)
        raise CarNotFoundException()

    image_with_boxes_for_car = (
        ImageProcessingService.draw_bounding_boxes_with_class_entity(
            image, first_result, max_number_of_boxes=5, show_only_score=True
        )
    )
    image_with_boxes_for_car.save(filename_sufix=&#34;car&#34;)

    image_links = {}
    image_links[&#34;car-boxes&#34;] = image_with_boxes_for_car.save_to_minio(
        filename_sufix=&#34;car-boxes&#34;
    )

    image_with_bottom_of_car = ImageProcessingService.crop_image(
        cropped_car, self._bottom_of_car_box
    )
    image_with_bottom_of_car.save(filename_sufix=&#34;bottom-car&#34;)
    image_links[&#34;cropped-car&#34;] = cropped_car.save_to_minio(
        filename_sufix=&#34;cropped-car&#34;
    )
    image_links[&#34;bottom-of-car&#34;] = image_with_bottom_of_car.save_to_minio(
        filename_sufix=&#34;bottom-of-car&#34;
    )

    try:
        (
            second_result,
            potential_license_plate,
            cropped_license_plate,
        ) = self.get_results_and_cropped_image_for_potential_object_of_class_entity(
            image_with_bottom_of_car,
            self._license_plate_class_entity,
            area_threshold=0,
            score_threshold=0.0,
        )
    except PotentialObjectNotFoundException as e:
        log.error(e)
        raise LicensePlateNotFoundException

    cropped_license_plate.save(filename_sufix=&#34;cropped-license-plate&#34;)
    image_links[&#34;cropped-license-plate&#34;] = cropped_license_plate.save_to_minio(
        filename_sufix=&#34;cropped-license-plate&#34;
    )

    image_with_boxes_for_plate = (
        ImageProcessingService.draw_bounding_boxes_with_class_entity(
            image_with_bottom_of_car,
            second_result,
            max_number_of_boxes=5,
            show_only_score=True,
        )
    )
    image_with_boxes_for_plate.save(filename_sufix=&#34;license-plate&#34;)
    image_links[&#34;license-plate-boxes&#34;] = image_with_boxes_for_plate.save_to_minio(
        filename_sufix=&#34;license-plate-boxes&#34;
    )

    try:
        ocr_result = self.send_image_to_ocr(cropped_license_plate)
    except CharactersCouldNotBeRecognizedByOCR:
        raise

    log.debug(ocr_result)

    ocr_result.image_links.update(**image_links)

    return ocr_result</code></pre>
</details>
</dd>
<dt id="inference_service.InferenceService.get_results_and_cropped_image_for_potential_object_of_class_entity"><code class="name flex">
<span>def <span class="ident">get_results_and_cropped_image_for_potential_object_of_class_entity</span></span>(<span>self, image: models.image.Image, class_entity: str, area_threshold: int = 20, score_threshold: float = 0.2) ‑> Tuple[List[models.detection_result.DetectionResult], models.detection_result.DetectionResult, models.image.Image]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns filtered result, result with potential object and image with that potential object.</p>
<p>Sends image to predict api for getting object detection result.
Then filters that result by class_entity (e.g. "Car")
and trying to find potential object of class_entity.
If potential object is found, image is cropped to its box and returned.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_results_and_cropped_image_for_potential_object_of_class_entity(
    self,
    image: Image,
    class_entity: str,
    area_threshold: int = 20,
    score_threshold: float = 0.2,
) -&gt; Tuple[List[DetectionResult], DetectionResult, Image]:
    &#34;&#34;&#34;Returns filtered result, result with potential object and image with that potential object.

    Sends image to predict api for getting object detection result.
    Then filters that result by class_entity (e.g. &#34;Car&#34;)
    and trying to find potential object of class_entity.
    If potential object is found, image is cropped to its box and returned.
    &#34;&#34;&#34;

    result = self.send_image_to_detector(image)
    result_filtered_by_class_entity = list(
        filter(
            lambda r: r.class_entity == class_entity,
            result,
        )
    )

    log.debug(result_filtered_by_class_entity)

    try:
        detection_result_of_potential_object = self.find_potential_object(
            result_filtered_by_class_entity,
            area_threshold=area_threshold,
            score_threshold=score_threshold,
        )
    except PotentialObjectNotFoundException:
        raise

    cropped_image_with_potential_object = ImageProcessingService.crop_image(
        image, detection_result_of_potential_object.box
    )

    return (
        result_filtered_by_class_entity,
        detection_result_of_potential_object,
        cropped_image_with_potential_object,
    )</code></pre>
</details>
</dd>
<dt id="inference_service.InferenceService.send_image_to_detector"><code class="name flex">
<span>def <span class="ident">send_image_to_detector</span></span>(<span>self, image: models.image.Image) ‑> List[models.detection_result.DetectionResult]</span>
</code></dt>
<dd>
<div class="desc"><p>Sends image to predict api, which returns JSON with predictions about objects in that image.
Before sending image, it needs to be encoded in base64.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_image_to_detector(self, image: Image) -&gt; List[DetectionResult]:
    &#34;&#34;&#34;Sends image to predict api, which returns JSON with predictions about objects in that image.
    Before sending image, it needs to be encoded in base64.
    &#34;&#34;&#34;
    image_base64 = image.to_base64()

    response = requests.post(
        f&#34;http://{predict_api_host}/predict&#34;,
        json={&#34;imgBase64&#34;: image_base64},
    )

    results = DetectionResultsDecoder().decode(response.text)

    return results</code></pre>
</details>
</dd>
<dt id="inference_service.InferenceService.send_image_to_ocr"><code class="name flex">
<span>def <span class="ident">send_image_to_ocr</span></span>(<span>self, image: models.image.Image) ‑> models.ocr_result.OcrResult</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def send_image_to_ocr(self, image: Image) -&gt; OcrResult:
    image_base64 = image.to_base64()

    response = requests.post(
        f&#34;http://{ocr_server_host}/ocr/base64&#34;,
        json={&#34;b64Encoded&#34;: image_base64},
    )

    print(response.status_code)
    if response.status_code != 200:
        raise CharactersCouldNotBeRecognizedByOCR

    return OcrResult.from_json(response.json())</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="inference_service.InferenceService" href="#inference_service.InferenceService">InferenceService</a></code></h4>
<ul class="">
<li><code><a title="inference_service.InferenceService.find_potential_object" href="#inference_service.InferenceService.find_potential_object">find_potential_object</a></code></li>
<li><code><a title="inference_service.InferenceService.get_license_plate_number" href="#inference_service.InferenceService.get_license_plate_number">get_license_plate_number</a></code></li>
<li><code><a title="inference_service.InferenceService.get_results_and_cropped_image_for_potential_object_of_class_entity" href="#inference_service.InferenceService.get_results_and_cropped_image_for_potential_object_of_class_entity">get_results_and_cropped_image_for_potential_object_of_class_entity</a></code></li>
<li><code><a title="inference_service.InferenceService.send_image_to_detector" href="#inference_service.InferenceService.send_image_to_detector">send_image_to_detector</a></code></li>
<li><code><a title="inference_service.InferenceService.send_image_to_ocr" href="#inference_service.InferenceService.send_image_to_ocr">send_image_to_ocr</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>